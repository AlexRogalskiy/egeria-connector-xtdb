Name:         p0160-10-kafka-0
Namespace:    default
Priority:     0
Node:         cgk8s-node-3.fyre.ibm.com/9.20.194.199
Start Time:   Sat, 11 Dec 2021 20:15:02 -0800
Labels:       app.kubernetes.io/component=kafka
              app.kubernetes.io/instance=p0160-10
              app.kubernetes.io/managed-by=Helm
              app.kubernetes.io/name=kafka
              controller-revision-hash=p0160-10-kafka-74bc4d8665
              helm.sh/chart=kafka-14.4.1
              statefulset.kubernetes.io/pod-name=p0160-10-kafka-0
Annotations:  cni.projectcalico.org/containerID: 5f7f15876073af03660f0932e8e6c3a0bec14bdf48ebc13552a01257c5151638
              cni.projectcalico.org/podIP: 10.233.64.127/32
              cni.projectcalico.org/podIPs: 10.233.64.127/32
Status:       Running
IP:           10.233.64.127
IPs:
  IP:           10.233.64.127
Controlled By:  StatefulSet/p0160-10-kafka
Containers:
  kafka:
    Container ID:  docker://37956563f313ed822b23380fc86197d222f4e5e2c2755e6c0e1f62f479db8bba
    Image:         docker.io/bitnami/kafka:2.8.1-debian-10-r31
    Image ID:      docker-pullable://bitnami/kafka@sha256:983db4159a4010d11b8698cec4869adae000ebba2fd3369af2314c48a24c2b5a
    Ports:         9092/TCP, 9093/TCP
    Host Ports:    0/TCP, 0/TCP
    Command:
      /scripts/setup.sh
    State:          Running
      Started:      Sat, 11 Dec 2021 20:15:05 -0800
    Ready:          True
    Restart Count:  0
    Liveness:       tcp-socket :kafka-client delay=10s timeout=5s period=10s #success=1 #failure=3
    Readiness:      tcp-socket :kafka-client delay=5s timeout=5s period=10s #success=1 #failure=6
    Environment:
      BITNAMI_DEBUG:                                       false
      MY_POD_IP:                                            (v1:status.podIP)
      MY_POD_NAME:                                         p0160-10-kafka-0 (v1:metadata.name)
      KAFKA_CFG_ZOOKEEPER_CONNECT:                         p0160-10-zookeeper
      KAFKA_INTER_BROKER_LISTENER_NAME:                    INTERNAL
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP:            INTERNAL:PLAINTEXT,CLIENT:PLAINTEXT
      KAFKA_CFG_LISTENERS:                                 INTERNAL://:9093,CLIENT://:9092
      KAFKA_CFG_ADVERTISED_LISTENERS:                      INTERNAL://$(MY_POD_NAME).p0160-10-kafka-headless.default.svc.cluster.local:9093,CLIENT://$(MY_POD_NAME).p0160-10-kafka-headless.default.svc.cluster.local:9092
      ALLOW_PLAINTEXT_LISTENER:                            yes
      KAFKA_VOLUME_DIR:                                    /bitnami/kafka
      KAFKA_LOG_DIR:                                       /opt/bitnami/kafka/logs
      KAFKA_CFG_DELETE_TOPIC_ENABLE:                       false
      KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE:                 true
      KAFKA_HEAP_OPTS:                                     -Xmx1024m -Xms1024m
      KAFKA_CFG_LOG_FLUSH_INTERVAL_MESSAGES:               10000
      KAFKA_CFG_LOG_FLUSH_INTERVAL_MS:                     1000
      KAFKA_CFG_LOG_RETENTION_BYTES:                       1073741824
      KAFKA_CFG_LOG_RETENTION_CHECK_INTERVALS_MS:          300000
      KAFKA_CFG_LOG_RETENTION_HOURS:                       168
      KAFKA_CFG_MESSAGE_MAX_BYTES:                         1000012
      KAFKA_CFG_LOG_SEGMENT_BYTES:                         1073741824
      KAFKA_CFG_LOG_DIRS:                                  /bitnami/kafka/data
      KAFKA_CFG_DEFAULT_REPLICATION_FACTOR:                1
      KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR:          1
      KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR:  1
      KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR:             1
      KAFKA_CFG_NUM_IO_THREADS:                            8
      KAFKA_CFG_NUM_NETWORK_THREADS:                       3
      KAFKA_CFG_NUM_PARTITIONS:                            1
      KAFKA_CFG_NUM_RECOVERY_THREADS_PER_DATA_DIR:         1
      KAFKA_CFG_SOCKET_RECEIVE_BUFFER_BYTES:               102400
      KAFKA_CFG_SOCKET_REQUEST_MAX_BYTES:                  104857600
      KAFKA_CFG_SOCKET_SEND_BUFFER_BYTES:                  102400
      KAFKA_CFG_ZOOKEEPER_CONNECTION_TIMEOUT_MS:           6000
      KAFKA_CFG_AUTHORIZER_CLASS_NAME:                     
      KAFKA_CFG_ALLOW_EVERYONE_IF_NO_ACL_FOUND:            true
      KAFKA_CFG_SUPER_USERS:                               User:admin
    Mounts:
      /bitnami/kafka from data (rw)
      /opt/bitnami/kafka/logs from logs (rw)
      /scripts/setup.sh from scripts (rw,path="setup.sh")
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-nvsl2 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  scripts:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      p0160-10-kafka-scripts
    Optional:  false
  data:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
  logs:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
  kube-api-access-nvsl2:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:                      <none>

Name:         p0160-10-pts-54c858468c-z5tnm
Namespace:    default
Priority:     0
Node:         cgk8s-node-1.fyre.ibm.com/9.20.193.94
Start Time:   Sat, 11 Dec 2021 20:15:02 -0800
Labels:       app.kubernetes.io/component=pts
              app.kubernetes.io/instance=p0160-10
              app.kubernetes.io/name=egeria-pts
              pod-template-hash=54c858468c
Annotations:  cni.projectcalico.org/containerID: 8d56e54184fbb9b0ec7a115401dbd38237da2a1a4ac12d427c0286b5a8898b14
              cni.projectcalico.org/podIP: 10.233.72.60/32
              cni.projectcalico.org/podIPs: 10.233.72.60/32
Status:       Running
IP:           10.233.72.60
IPs:
  IP:           10.233.72.60
Controlled By:  ReplicaSet/p0160-10-pts-54c858468c
Containers:
  pts:
    Container ID:   docker://84992de73a3def5447d5f6b9f5d97b5151ef9549526b71ee5f035137adce1feb
    Image:          quay.io/odpi/egeria:3.4
    Image ID:       docker-pullable://quay.io/odpi/egeria@sha256:23b744197d2a90a1a087dee308ad74e5f9e451c33f5571b3524cbb1eaf05bfa7
    Port:           9443/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Sat, 11 Dec 2021 20:15:05 -0800
    Ready:          True
    Restart Count:  0
    Limits:
      cpu:     4
      memory:  16Gi
    Requests:
      cpu:      2
      memory:   8Gi
    Readiness:  tcp-socket :9443 delay=10s timeout=1s period=10s #success=1 #failure=6
    Environment Variables from:
      p0160-10-env  ConfigMap  Optional: false
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-n6l4n (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  kube-api-access-n6l4n:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   Burstable
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:                      <none>

Name:         p0160-10-report-khcxk
Namespace:    default
Priority:     0
Node:         cgk8s-node-3.fyre.ibm.com/9.20.194.199
Start Time:   Sat, 11 Dec 2021 20:15:02 -0800
Labels:       app.kubernetes.io/component=report
              app.kubernetes.io/instance=p0160-10
              app.kubernetes.io/name=egeria-pts
              controller-uid=d150a896-9719-4774-a0bc-9ebc0cf68190
              job-name=p0160-10-report
Annotations:  cni.projectcalico.org/containerID: 67befab1fa6dd1b2d611d1ac4cfd215ba1fbbafbc25cdffc1dca141b15e17a85
              cni.projectcalico.org/podIP: 10.233.64.126/32
              cni.projectcalico.org/podIPs: 10.233.64.126/32
Status:       Running
IP:           10.233.64.126
IPs:
  IP:           10.233.64.126
Controlled By:  Job/p0160-10-report
Init Containers:
  wait-for-pts:
    Container ID:   docker://df940bc1ebd8cfe9ca8b37aeeed2be4bc5a6e48331e4118aa990bede85ba80ab
    Image:          quay.io/odpi/egeria-configure:3.4
    Image ID:       docker-pullable://quay.io/odpi/egeria-configure@sha256:948a5b8aec1795cd9b9d4b8d8a86ad11aaf3f0eaf2b1a28fa9543d2b7f0b0217
    Port:           <none>
    Host Port:      <none>
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 11 Dec 2021 20:15:05 -0800
      Finished:     Sat, 11 Dec 2021 20:15:32 -0800
    Ready:          True
    Restart Count:  0
    Environment:
      SERVICE:  p0160-10-pts
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-f8t92 (ro)
  wait-for-kafka:
    Container ID:   docker://5a7e1e168daff8d345c81eed32618a429c00eaf2a0be961445ec4a26f86e3138
    Image:          quay.io/odpi/egeria-configure:3.4
    Image ID:       docker-pullable://quay.io/odpi/egeria-configure@sha256:948a5b8aec1795cd9b9d4b8d8a86ad11aaf3f0eaf2b1a28fa9543d2b7f0b0217
    Port:           <none>
    Host Port:      <none>
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 11 Dec 2021 20:15:33 -0800
      Finished:     Sat, 11 Dec 2021 20:15:33 -0800
    Ready:          True
    Restart Count:  0
    Environment:
      SERVICE:  p0160-10-kafka
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-f8t92 (ro)
  wait-for-tut:
    Container ID:   docker://71c062b678bc3e96f518b892515d2cc307895053e70cec8ec2332f2787b7a81d
    Image:          quay.io/odpi/egeria-configure:3.4
    Image ID:       docker-pullable://quay.io/odpi/egeria-configure@sha256:948a5b8aec1795cd9b9d4b8d8a86ad11aaf3f0eaf2b1a28fa9543d2b7f0b0217
    Port:           <none>
    Host Port:      <none>
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 11 Dec 2021 20:15:34 -0800
      Finished:     Sat, 11 Dec 2021 20:15:34 -0800
    Ready:          True
    Restart Count:  0
    Environment:
      SERVICE:  p0160-10-tut
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-f8t92 (ro)
  wait-for-init:
    Container ID:  docker://b18fe4a8cebdc40bd2fb2d12e9a61bfedf11a7be4a9ef6c3d7a62e6b7ed79f61
    Image:         quay.io/odpi/egeria-configure:3.4
    Image ID:      docker-pullable://quay.io/odpi/egeria-configure@sha256:948a5b8aec1795cd9b9d4b8d8a86ad11aaf3f0eaf2b1a28fa9543d2b7f0b0217
    Port:          <none>
    Host Port:     <none>
    Command:
      /bin/bash
      -c
      /scripts/wait-for-init.sh
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 11 Dec 2021 20:15:35 -0800
      Finished:     Sat, 11 Dec 2021 20:15:46 -0800
    Ready:          True
    Restart Count:  0
    Environment Variables from:
      p0160-10-env  ConfigMap  Optional: false
    Environment:    <none>
    Mounts:
      /scripts from scripts-vol (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-f8t92 (ro)
  report:
    Container ID:  docker://a38f299986f2d3e39fd03d759333233055e9df7b56267e95b907a000cebb1aec
    Image:         quay.io/odpi/egeria-configure:3.4
    Image ID:      docker-pullable://quay.io/odpi/egeria-configure@sha256:948a5b8aec1795cd9b9d4b8d8a86ad11aaf3f0eaf2b1a28fa9543d2b7f0b0217
    Port:          <none>
    Host Port:     <none>
    Command:
      /bin/bash
      -c
      /scripts/collect-results.sh
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 11 Dec 2021 20:15:47 -0800
      Finished:     Wed, 15 Dec 2021 13:00:09 -0800
    Ready:          True
    Restart Count:  0
    Limits:
      cpu:     1
      memory:  512Mi
    Requests:
      cpu:     200m
      memory:  64Mi
    Environment Variables from:
      p0160-10-env  ConfigMap  Optional: false
    Environment:    <none>
    Mounts:
      /export from output-files (rw)
      /scripts from scripts-vol (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-f8t92 (ro)
Containers:
  wait-for-retrieval:
    Container ID:  docker://7320e3a408f719bf5713d6557dbfc7988be211e716876b3d0d629cfc2158f6d9
    Image:         quay.io/odpi/egeria-configure:3.4
    Image ID:      docker-pullable://quay.io/odpi/egeria-configure@sha256:948a5b8aec1795cd9b9d4b8d8a86ad11aaf3f0eaf2b1a28fa9543d2b7f0b0217
    Port:          <none>
    Host Port:     <none>
    Command:
      /bin/sh
      -c
    Args:
      set -e
      echo "Creating a fifo pipe to send the output data"
      mkfifo /export/pipe
      echo "You'll need to stream the files out for this pod to shutdown, using a command like:"
      echo "kubectl exec POD_NAME -- sh -c 'cat /export/pipe' | tar -xvf -"
      cd /export
      tar -cvf - /export/${PTS_REPORT_NAME}.tar.gz > /export/pipe
      echo "The files have been read, the previous command stopped blocking, will wait for final cleanup..."
      sleep 10
      echo "Will now exit."
      
    State:          Running
      Started:      Wed, 15 Dec 2021 13:00:10 -0800
    Ready:          True
    Restart Count:  0
    Environment Variables from:
      p0160-10-env  ConfigMap  Optional: false
    Environment:    <none>
    Mounts:
      /export from output-files (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-f8t92 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  output-files:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
  scripts-vol:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      p0160-10-scripts-configmap
    Optional:  false
  kube-api-access-f8t92:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   Burstable
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason   Age   From     Message
  ----    ------   ----  ----     -------
  Normal  Pulled   70s   kubelet  Container image "quay.io/odpi/egeria-configure:3.4" already present on machine
  Normal  Created  70s   kubelet  Created container wait-for-retrieval
  Normal  Started  70s   kubelet  Started container wait-for-retrieval

Name:         p0160-10-tut-7bbb4d979f-5bcrj
Namespace:    default
Priority:     0
Node:         cgk8s-node-1.fyre.ibm.com/9.20.193.94
Start Time:   Sat, 11 Dec 2021 20:15:02 -0800
Labels:       app.kubernetes.io/component=tut
              app.kubernetes.io/instance=p0160-10
              app.kubernetes.io/name=egeria-pts
              pod-template-hash=7bbb4d979f
Annotations:  cni.projectcalico.org/containerID: 5dc3cc7c2cde9242c529f595c4e20161164f0fa2697dadc06843bba3a65b1c2a
              cni.projectcalico.org/podIP: 10.233.72.61/32
              cni.projectcalico.org/podIPs: 10.233.72.61/32
Status:       Running
IP:           10.233.72.61
IPs:
  IP:           10.233.72.61
Controlled By:  ReplicaSet/p0160-10-tut-7bbb4d979f
Init Containers:
  init-connector:
    Container ID:  docker://e6c0bd756d932b59138f07c0a912659deb987be183f92bd6abd3aff978dbc069
    Image:         quay.io/odpi/egeria-configure:3.4
    Image ID:      docker-pullable://quay.io/odpi/egeria-configure@sha256:948a5b8aec1795cd9b9d4b8d8a86ad11aaf3f0eaf2b1a28fa9543d2b7f0b0217
    Port:          <none>
    Host Port:     <none>
    Command:
      /bin/bash
      -c
      cd /opt/egeria/connectors &&
      curl --location "http://repository.sonatype.org/service/local/artifact/maven/redirect?r=central-proxy&g=org.odpi.egeria&a=egeria-connector-xtdb&v=RELEASE&c=jar-with-dependencies" --output "egeria-connector-xtdb-jar-with-dependencies.jar" &&
      echo "Downloads complete."
      
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 11 Dec 2021 20:15:05 -0800
      Finished:     Sat, 11 Dec 2021 20:15:09 -0800
    Ready:          True
    Restart Count:  0
    Environment Variables from:
      p0160-10-env  ConfigMap  Optional: false
    Environment:    <none>
    Mounts:
      /opt/egeria/connectors from egeria-connector-volume (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-qrtgw (ro)
Containers:
  tut:
    Container ID:   docker://e4a296ff08836662611c846ea4360089b03bf7c98a5ce677ba29fa6a8fadb7d9
    Image:          quay.io/odpi/egeria:3.4
    Image ID:       docker-pullable://quay.io/odpi/egeria@sha256:23b744197d2a90a1a087dee308ad74e5f9e451c33f5571b3524cbb1eaf05bfa7
    Port:           9443/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Sat, 11 Dec 2021 20:15:11 -0800
    Ready:          True
    Restart Count:  0
    Limits:
      cpu:     4
      memory:  16Gi
    Requests:
      cpu:      2
      memory:   8Gi
    Readiness:  tcp-socket :9443 delay=10s timeout=1s period=10s #success=1 #failure=6
    Environment Variables from:
      p0160-10-env  ConfigMap  Optional: false
    Environment:
      LOADER_PATH:  /opt/egeria/connectors
    Mounts:
      /opt/egeria/connectors from egeria-connector-volume (ro)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-qrtgw (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  egeria-connector-volume:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
  kube-api-access-qrtgw:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   Burstable
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:                      <none>

Name:         p0160-10-zookeeper-0
Namespace:    default
Priority:     0
Node:         cgk8s-node-1.fyre.ibm.com/9.20.193.94
Start Time:   Sat, 11 Dec 2021 20:15:02 -0800
Labels:       app.kubernetes.io/component=zookeeper
              app.kubernetes.io/instance=p0160-10
              app.kubernetes.io/managed-by=Helm
              app.kubernetes.io/name=zookeeper
              controller-revision-hash=p0160-10-zookeeper-7d57cbc4d5
              helm.sh/chart=zookeeper-7.4.10
              statefulset.kubernetes.io/pod-name=p0160-10-zookeeper-0
Annotations:  cni.projectcalico.org/containerID: 6780de7e113e0824387a9ede71544934af803766f9bb59b3baab3773f99cc327
              cni.projectcalico.org/podIP: 10.233.72.62/32
              cni.projectcalico.org/podIPs: 10.233.72.62/32
Status:       Running
IP:           10.233.72.62
IPs:
  IP:           10.233.72.62
Controlled By:  StatefulSet/p0160-10-zookeeper
Containers:
  zookeeper:
    Container ID:  docker://2a7db11d489ca31a386ff4c98425554c939f0e292cf6754795cdcaea5cc91b2a
    Image:         docker.io/bitnami/zookeeper:3.7.0-debian-10-r188
    Image ID:      docker-pullable://bitnami/zookeeper@sha256:0a9806c3d24d1b31e534ad660beca298deb25a46048b74995539da79feb25f53
    Ports:         2181/TCP, 2888/TCP, 3888/TCP
    Host Ports:    0/TCP, 0/TCP, 0/TCP
    Command:
      bash
      -ec
      # Execute entrypoint as usual after obtaining ZOO_SERVER_ID
      # check ZOO_SERVER_ID in persistent volume via myid
      # if not present, set based on POD hostname
      if [[ -f "/bitnami/zookeeper/data/myid" ]]; then
        export ZOO_SERVER_ID="$(cat /bitnami/zookeeper/data/myid)"
      else
        HOSTNAME=`hostname -s`
        if [[ $HOSTNAME =~ (.*)-([0-9]+)$ ]]; then
          ORD=${BASH_REMATCH[2]}
          export ZOO_SERVER_ID=$((ORD + 1 ))
        else
          echo "Failed to get index from hostname $HOST"
          exit 1
        fi
      fi
      exec /entrypoint.sh /run.sh
      
    State:          Running
      Started:      Sat, 11 Dec 2021 20:15:05 -0800
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:      250m
      memory:   256Mi
    Liveness:   exec [/bin/bash -c echo "ruok" | timeout 2 nc -w 2 localhost 2181 | grep imok] delay=30s timeout=5s period=10s #success=1 #failure=6
    Readiness:  exec [/bin/bash -c echo "ruok" | timeout 2 nc -w 2 localhost 2181 | grep imok] delay=5s timeout=5s period=10s #success=1 #failure=6
    Environment:
      BITNAMI_DEBUG:               false
      ZOO_DATA_LOG_DIR:            
      ZOO_PORT_NUMBER:             2181
      ZOO_TICK_TIME:               2000
      ZOO_INIT_LIMIT:              10
      ZOO_SYNC_LIMIT:              5
      ZOO_PRE_ALLOC_SIZE:          65536
      ZOO_SNAPCOUNT:               100000
      ZOO_MAX_CLIENT_CNXNS:        60
      ZOO_4LW_COMMANDS_WHITELIST:  srvr, mntr, ruok
      ZOO_LISTEN_ALLIPS_ENABLED:   no
      ZOO_AUTOPURGE_INTERVAL:      0
      ZOO_AUTOPURGE_RETAIN_COUNT:  3
      ZOO_MAX_SESSION_TIMEOUT:     40000
      ZOO_SERVERS:                 p0160-10-zookeeper-0.p0160-10-zookeeper-headless.default.svc.cluster.local:2888:3888::1
      ZOO_ENABLE_AUTH:             no
      ZOO_HEAP_SIZE:               1024
      ZOO_LOG_LEVEL:               ERROR
      ALLOW_ANONYMOUS_LOGIN:       yes
      POD_NAME:                    p0160-10-zookeeper-0 (v1:metadata.name)
    Mounts:
      /bitnami/zookeeper from data (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-kvbpk (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  data:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
  kube-api-access-kvbpk:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   Burstable
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason     Age                   From     Message
  ----     ------     ----                  ----     -------
  Warning  Unhealthy  11m (x15 over 3d16h)  kubelet  Liveness probe failed:
  Warning  Unhealthy  11m (x15 over 3d16h)  kubelet  Readiness probe failed:

